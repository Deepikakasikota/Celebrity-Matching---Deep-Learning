# -*- coding: utf-8 -*-
"""feature_extraction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MC6s0GTgH7QFlg7bSLkrpDiQ5x0qvbmC
"""

drive.mount('/content/drive')  # import drive

from google.colab import drive    # connect to google drive

"""# Celebrity Face Matching:

## Import Required Libraries:
"""
'''
!pip install mtcnn==0.1.0

!pip install tensorflow==2.3.1

!pip install keras==2.4.3

!pip install keras-vggface==0.6

!pip install keras_applications==1.0.8
'''
# list the actors..

import os
actors = os.listdir('/content/drive/MyDrive/Colab Notebooks/data')
actors

len(actors)

# save the image path into filenames..

filenames = []

for actor in actors:
  for file in os.listdir(os.path.join('/content/drive/MyDrive/Colab Notebooks/data',actor)):
    filenames.append(os.path.join('/content/drive/MyDrive/Colab Notebooks/data',actor,file))

print(filenames)
print(len(filenames))

# save the file using pickle..

import pickle
pickle.dump(filenames,open('filenames.pkl','wb'))

from tensorflow.keras.preprocessing import image
from keras_vggface.utils import preprocess_input
from keras_vggface.vggface import VGGFace
import numpy as np
from tqdm import tqdm

filenames = pickle.load(open('/content/filenames.pkl','rb'))

# model training using 'resnet50' Transfer learning...

model = VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3),pooling='avg')

def feature_extractor(img_path,model):
  img = image.load_img(img_path,target_size=(224,224))
  img_array = image.img_to_array(img)
  expanded_img = np.expand_dims(img_array,axis=0)
  preprocessed_img = preprocess_input(expanded_img)

  result = model.predict(preprocessed_img).flatten()
  return result

# save the model in pickle file..

features = []

for file in tqdm(filenames):
  features.append(feature_extractor(file,model))

pickle.dump(features,open('embedding.pkl','wb'))